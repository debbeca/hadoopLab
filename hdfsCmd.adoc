* To avoid any security problem, we need to first generate a public key and add it to knownhosts :
-----------------
ssh-keygen -t rsa -P ""
cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys
ssh localhost
-----------------

* To format the name node: to exec on a fresh new hadoop fs
-----------------
hdfs namenode -format  
-----------------

* Start the dfs deamon 
-----------------
start-dfs.sh   
-----------------

* Start the Yarn deamon 
-----------------
start-yarn.sh   
-----------------

* Monitor java deamons
-----------------
jps  
-----------------

* In order to create a hdfs directory .. first create the 'user directory' then create your folder
-----------------
hdfs dfs -mkdir -p /user/[your current user]
hdfs dfs -mkdir -p /user/[your current user]/input
-----------------

* you also need to give to the user access to the hadoop folder :
-----------------
hadoop fs -chown username:username /user/username
-----------------

* monitor & report hdfs state
-----------------
hdfs dfsadmin -report
-----------------



* source :
- no such directory problem :
http://stackoverflow.com/questions/20821584/hadoop-2-2-installation-no-such-file-or-directory
- Native jvm :
http://stackoverflow.com/questions/19943766/hadoop-unable-to-load-native-hadoop-library-for-your-platform-warning/19993403#19993403

